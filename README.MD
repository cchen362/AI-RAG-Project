# AI-RAG-Project: Multi-Source RAG with Visual Understanding

A sophisticated **Retrieval-Augmented Generation (RAG)** system that combines **Text RAG**, **ColPali visual document understanding**, and **Salesforce integration** with intelligent source selection for enterprise-grade document processing.

## âœ¨ Key Features

- **ğŸ” Multi-Source Intelligence**: Text embeddings + ColPali visual understanding + Salesforce knowledge base
- **ğŸ–¼ï¸ Visual Document Processing**: ColPali processes PDFs directly as images (no OCR required)
- **ğŸ§  BGE Re-ranker**: Intelligent semantic source selection using BAAI/bge-reranker-base
- **âš¡ Instant Docker Startup**: Pre-loaded models enable 0-5 second container startup (vs 2-3 minutes)
- **ğŸ”¥ GPU & CPU Support**: Hardware-optimized deployments with automatic detection
- **ğŸš€ Auto-initialization**: Seamless user experience with loading indicators
- **ğŸŒ Cross-Platform**: Windows, Linux, macOS support with intelligent poppler detection
- **ğŸ›¡ï¸ Graceful Degradation**: Text RAG continues working when visual processing unavailable
- **ğŸ“‹ System Status**: Real-time feature availability indicators in UI
- **ğŸ’° Token Transparency**: 6-column token breakdown for cost monitoring
- **ğŸ“Š Production Ready**: Comprehensive health monitoring and container orchestration

## ğŸš€ Quick Start

### **Option 1: Docker Deployment (Recommended)**
```bash
# CPU-optimized instant startup
docker-compose up ai-rag-app

# GPU-accelerated deployment (requires nvidia-docker)
docker-compose --profile gpu up ai-rag-app-gpu

# Production deployment (detached)
docker-compose up -d ai-rag-app
```
Access at: **http://localhost:8501**

### **Option 2: Local Development**
```bash
# Clone and setup
git clone https://github.com/cchen362/AI-RAG-Project
cd AI-RAG-Project
pip install -r requirements.txt

# Launch application
streamlit run streamlit_rag_app.py
```

### **Option 3: Quick Launcher**
```bash
python launch_app.py
```

## ğŸ—ï¸ Architecture Overview

### **Multi-Source Query Processing**
```
User Query â†’ SimpleRAGOrchestrator â†’ [Text RAG | ColPali Visual | Salesforce] 
                    â†“
           BGE Cross-Encoder Re-ranker â†’ Single Best Response
```

### **Core Components**
- **SimpleRAGOrchestrator**: Coordinates multi-source search and response generation
- **BGE Cross-Encoder**: Semantic source selection (replaces rule-based intent logic)
- **ColPali Integration**: Visual document understanding using vidore/colqwen2-v1.0
- **Token Counter**: Comprehensive usage tracking for cost transparency

### **Model Specifications**
- **Text Embeddings**: all-MiniLM-L6-v2 (local) or OpenAI text-embedding-ada-002
- **Visual Understanding**: ColQwen2-v1.0 (ColPali engine)
- **Re-ranking**: BAAI/bge-reranker-base
- **Vector Database**: FAISS with metadata support

## ğŸ“ Project Structure

```
AI-RAG-Project/
â”œâ”€â”€ streamlit_rag_app.py          # Main production application
â”œâ”€â”€ launch_app.py                 # Development launcher utility
â”œâ”€â”€ requirements.txt              # Python dependencies  
â”œâ”€â”€ Dockerfile                    # Multi-stage container build
â”œâ”€â”€ docker-compose.yml            # GPU support & orchestration
â”œâ”€â”€ .dockerignore                 # Optimized build context
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ warm_up_models.py         # Model pre-loading for Docker
â”‚   â””â”€â”€ health_check.py           # Container health monitoring
â”œâ”€â”€ src/                          # Core components (7 files)
â”‚   â”œâ”€â”€ rag_system.py            # Main RAG orchestrator
â”‚   â”œâ”€â”€ colpali_retriever.py     # Visual document understanding  
â”‚   â”œâ”€â”€ salesforce_connector.py  # External data integration
â”‚   â”œâ”€â”€ cross_encoder_reranker.py # Intelligent source selection
â”‚   â”œâ”€â”€ document_processor.py    # Document processing pipeline
â”‚   â”œâ”€â”€ text_chunker.py          # Text chunking utilities
â”‚   â””â”€â”€ embedding_manager.py     # Embedding management
â”œâ”€â”€ data/documents/              # Document storage
â”œâ”€â”€ cache/embeddings/            # Runtime embedding cache
â””â”€â”€ CLAUDE.md                    # Development documentation
```

## ğŸŒ Cross-Platform Support

### **Platform Compatibility**
The system automatically detects and adapts to different operating systems:

| Platform | Poppler Detection | Visual Processing | Fallback Behavior |
|----------|------------------|-------------------|-------------------|
| **Linux/Docker** | `/usr/bin`, `/usr/local/bin` | âœ… Full Support | Text RAG continues |
| **Windows** | Program Files, Conda paths | âœ… Full Support | Text RAG continues |
| **macOS** | Homebrew, MacPorts | âœ… Full Support | Text RAG continues |

### **Graceful Degradation**
When poppler is unavailable, the system provides clear feedback and continues operating:

```
âš ï¸ Visual Processing Status:
âœ… Text RAG: Available 
âš ï¸ Visual RAG (ColPali): Limited (Poppler unavailable)
âœ… Salesforce: Connected
âœ… Re-ranker: Active

ğŸ’¡ Install poppler-utils for visual document processing
```

### **System Requirements**
- **Required**: Python 3.9+, basic dependencies
- **Optional**: Poppler-utils (for visual processing)
- **Recommended**: GPU support for optimal performance

### **Installation Commands**
```bash
# Ubuntu/Debian
sudo apt-get install poppler-utils

# Windows (Conda)
conda install -c conda-forge poppler

# macOS (Homebrew)  
brew install poppler

# Docker (automatically included)
# No additional setup required
```

## ğŸ³ Docker Optimization

### **Instant Startup Performance**
| Deployment Mode | Startup Time | Model Loading | Memory Usage |
|-----------------|-------------|---------------|--------------|
| Local Development | 2-3 minutes | On-demand | Variable |
| Docker CPU | **0-5 seconds** | Pre-loaded | Optimized |
| Docker GPU | **0-5 seconds** | Pre-loaded | GPU-accelerated |

### **Multi-Stage Architecture**
```dockerfile
Stage 1 (model-builder): Download and cache all AI models
Stage 2 (production): Copy pre-loaded models + application code
Result: Instant startup with full functionality
```

### **Container Variants**
- **ai-rag-app** (Port 8501): CPU-optimized for standard deployments
- **ai-rag-app-gpu** (Port 8502): GPU-accelerated for high-performance processing
- **model-builder**: Development container for model management

### **Health Monitoring**
- Automated health checks every 30 seconds
- Model verification via manifest validation
- Streamlit health endpoint monitoring
- Container restart policies for reliability

## ğŸ’¡ Usage Examples

### **Multi-Source Queries**
The system automatically queries all sources and selects the best response:

```
Query: "What is the cancellation policy?"

Processing:
âœ“ Text RAG: Searches uploaded documents
âœ“ ColPali: Analyzes PDF images for visual information  
âœ“ Salesforce: Searches knowledge base articles

Result: BGE re-ranker selects best source (e.g., "SALESFORCE" score: 0.847)
Reasoning: "Salesforce KB article provides most comprehensive cancellation policy"
```

### **Visual Document Understanding**
ColPali processes PDFs as images, understanding layout and visual elements:
- Tables, charts, and diagrams
- Multi-column layouts
- Visual hierarchies and formatting
- No OCR pipeline required

### **Token Transparency**
6-column breakdown for cost monitoring:
| Query | VLM | Salesforce | Re-rank | Response | Total |
|-------|-----|------------|---------|----------|-------|
| 12 | 245 | 156 | 10 | 168 | 591 |

## âš™ï¸ Configuration

### **Environment Variables** (Optional)
```bash
# API Keys (local embeddings work without OpenAI)
OPENAI_API_KEY=your_openai_key

# Salesforce Integration
SALESFORCE_USERNAME=your_username@company.com
SALESFORCE_PASSWORD=your_password
SALESFORCE_SECURITY_TOKEN=your_security_token

# Cross-Platform Poppler Support (optional)
POPPLER_PATH=/custom/poppler/bin

# Docker Optimization
DOCKER_PRELOADED_MODELS=true
TRANSFORMERS_CACHE=/app/models/transformers
HF_HOME=/app/models/huggingface
```

### **Hardware Requirements**
- **Minimum**: 8GB RAM, 4 CPU cores
- **Recommended**: 16GB RAM, 8 CPU cores, GPU (optional)
- **Docker**: 4GB available to Docker Desktop
- **GPU**: CUDA-compatible for ColPali acceleration

## ğŸ› ï¸ Development

### **Local Testing**
```bash
# Test individual components
python scripts/health_check.py

# Test model loading
python scripts/warm_up_models.py

# Launch with debugging
streamlit run streamlit_rag_app.py --logger.level=debug
```

### **Docker Development**
```bash
# Build with model pre-loading
docker build -t ai-rag-app .

# Test specific profiles
docker-compose --profile build-models up model-builder
docker-compose --profile gpu up ai-rag-app-gpu

# Monitor health
docker exec ai-rag-cpu python scripts/health_check.py
```

## ğŸ“Š Technical Specifications

### **Performance Metrics**
- **Query Processing**: ~2-5 seconds (includes all sources + re-ranking)
- **Document Upload**: ~30-60 seconds per PDF (ColPali processing)
- **Model Loading**: Instant (Docker) vs 2-3 minutes (local)
- **Memory Usage**: ~2-4GB (CPU) / ~6-8GB (GPU)

### **Scalability Features**
- Stateless application design
- Horizontal scaling via container orchestration
- Persistent volume support for data and models
- Health-check based auto-recovery

## âœ… Current Status

**ğŸ¯ Production Ready (All Phases Complete)**
- âœ… **Phase 1**: Research & ColPali integration
- âœ… **Phase 2**: Production app with multi-source architecture  
- âœ… **Phase 3**: Docker optimization with instant startup
- âœ… **Cleanup**: Codebase optimization (56+ obsolete files removed)

**ğŸš€ Ready for:**
- Enterprise deployments with instant startup
- Kubernetes orchestration and scaling
- GPU-accelerated cloud environments
- Multi-tenant configurations

## ğŸ¤ Contributing

### **Development Workflow**
```bash
git checkout -b feature/your-feature-name
# Make changes
python scripts/health_check.py  # Verify functionality
git add .
git commit -m "feat: your feature description"
git push -u origin feature/your-feature-name
```

### **Testing Guidelines**
- Test both CPU and GPU configurations
- Verify Docker builds complete successfully
- Ensure health checks pass
- Validate multi-source query processing

## ğŸ”§ Troubleshooting

### **Common Issues**

#### **Visual Processing Unavailable**
```
âš ï¸ Visual RAG (ColPali): Limited (Poppler unavailable)
```
**Solution**: Install poppler-utils for your platform:
- Linux: `sudo apt-get install poppler-utils`  
- Windows: `conda install -c conda-forge poppler`
- macOS: `brew install poppler`
- Docker: Already included

#### **OpenAI API Key Warning** 
```
âš ï¸ OpenAI API key not found - visual analysis will be limited
```
**Solution**: Create `.env` file with:
```bash
OPENAI_API_KEY=your_key_here
```

#### **Slow Performance on CPU**
**Symptoms**: ColPali processing taking 30+ seconds per page
**Solution**: 
- Use GPU deployment: `docker-compose --profile gpu up ai-rag-app-gpu`
- Or accept CPU limitations with reduced page counts

#### **Docker Build Fails**
**Common causes**:
- Insufficient disk space (requires ~10GB)
- Network issues during model download
- CUDA version mismatch (GPU builds)

**Solution**:
```bash
# Clean Docker cache
docker system prune -a

# Rebuild with verbose output  
docker-compose build --no-cache --progress=plain
```

#### **Health Check Failures**
**Check status**:
```bash
# View container logs
docker logs ai-rag-cpu

# Manual health check
docker exec ai-rag-cpu python scripts/health_check.py
```

### **Environment Variable Reference**
| Variable | Purpose | Required |
|----------|---------|----------|
| `OPENAI_API_KEY` | Enhanced visual analysis | Optional |
| `POPPLER_PATH` | Custom poppler location | Optional |
| `SALESFORCE_*` | Knowledge base integration | Optional |
| `DOCKER_PRELOADED_MODELS` | Enable instant startup | Auto-set |

## ğŸ“„ License

MIT License - See LICENSE file for details

---

**Built with**: Custom Multi-Source RAG Pipeline, ColPali Visual Understanding, BGE Cross-Encoder, OpenAI/Sentence-Transformers, Salesforce API, Streamlit, FAISS, Docker

**Architecture**: SimpleRAGOrchestrator + BGE Re-ranker + ColPali + Instant Docker Startup