# AI-RAG-Project Requirements - Consolidated for CPU & GPU deployment
# Production tested on Linux server (August 2025)
# Automatically detects and uses GPU acceleration when available

# Core RAG Framework - Production tested components
langchain>=0.2.0
langchain-community>=0.2.0
langchain-openai>=0.1.0

# Vector Database - Auto-detects GPU/CPU for optimal performance
chromadb>=0.5.0
faiss-cpu>=1.7.4                 # Automatically uses GPU if available
# Alternative options (choose one):
# pinecone-client>=3.0.0
# weaviate-client>=4.0.0

# AI Models and Embeddings - Updated for 2025
openai>=1.50.0                   # Latest API with improved performance
sentence-transformers>=3.0.0
scikit-learn>=1.3.0

# Document Processing - Your "prep tools"
pypdf>=4.0.0
pdfplumber>=0.11.0
python-docx>=1.1.0
openpyxl>=3.1.0
pandas>=2.2.0

# Web Interface - Modern glassmorphism UI
streamlit>=1.40.0                # Latest stable with enhanced performance
streamlit-extras>=0.3.0          # For advanced UI components (stylable_container)

# Utilities - Your "kitchen helpers"
python-dotenv>=1.0.0
requests>=2.32.0
numpy>=1.26.0
matplotlib>=3.8.0
plotly>=5.20.0
simple-salesforce>=1.12.0
py-cpuinfo>=9.0.0                # CPU instruction set detection for old hardware compatibility

# Development Tools
jupyter>=1.0.0
notebook>=7.2.0

# ColPali Visual Embeddings - Production tested versions
colpali-engine>=0.3.10       # Latest stable version with transformers 4.50.0+ compatibility
pdf2image>=1.17.0            # PDF to image conversion
Pillow>=10.0.0               # Essential for image processing (PIL)
# Note: pdf2image requires poppler system dependency
# Windows: conda install -c conda-forge poppler
# Linux: apt-get install poppler-utils  
# macOS: brew install poppler

# AI Models - Updated for 2025 Compatibility
transformers>=4.50.0         # Required for latest ColPali models
torch>=2.5.1                 # Stable version, compatible with colpali-engine
accelerate>=0.33.0           # Hugging Face GPU acceleration utilities
# Note: flash-attn removed - optional performance optimization
# Install separately if needed: pip install flash-attn

# Re-ranker Architecture
tiktoken>=0.5.0              # Token counting for transparency